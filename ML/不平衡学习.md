### 不平衡学习

## 1. under-sample

欠采样的思想是丢掉样本集中多数类的样本.使得样本集中多数类和少数类类别平衡.简单的就是random欠采样.

### 1.1 Tomek links

假设样本点xi和xj属于不同的类别，d(xi,xj)表示两个样本点之间的距离。

称(xi,xj)为一个Tomek link对，如果不存在第三个样本点xl使得d(xl,xi)<d(xi,xj)或者d(xl,xj)<d(xi,xj)成立。



容易看出，如果两个样本点为Tomek link对，则其中某个样本为噪声（偏离正常分布太多）或者两个样本都在两类的边界上。

下图是对Tomek link对的直观解释（其中加号为少数类，减号为多数类）：A、B、C中的样本在两类的边界上，D、E中的多数类样本均为噪声



![](http://mmbiz.qpic.cn/mmbiz/kqd3L9d8WdBWjZqPwSJZKpgbntPuz9ia7b5H1C56ZK70TlicwUBaAialdqDD5VFFtfk72R8iaHEkZKdFLAsC0icUWOg/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

- 要么将 Tomek Links 对中多数类样本去掉
- 要么将两个样本都去掉

## 2. over_sample
过采样的思想就是往样本集合中重复加入少数类,使得样本类别平衡,但是重复复制样本比较容易导致过拟合.所以就有smote算法



### 2.1  smote

smote思想是通过在一些位置相近的少数类样本中生成新样本达到平衡类别的目的，由于不是简单地复制少数类样本，因此可以在一定程度上避免分类器的过度拟合。

**具体过程如下**

在少数类的样本集合T中随机选择一个样本,然后在少数类的集合T通过最近邻来搜索K个最近的样本点,然后进行插值.

![](http://mmbiz.qpic.cn/mmbiz/kqd3L9d8WdBWjZqPwSJZKpgbntPuz9ia767ZFehsTKw0Yo6qype1YMiaE7r7h0xnAV7fXVRREhgAVicbKXhNdcOicQ/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

### 2.2 borderline Smote

通过找到分类边界上比较难分的少数类样本点进行插值更容易提升模型的效果.

**具体过程如下**

- 对少数类的样本点x在整个数据集搜索K个样本点.如果K个样本点中少数类数量m超过一半,那么这个点认为是安全点,如果m=0,那么这个点就是噪声点.0~k/2 之间 认为是危险点.

- 然后对这些点用smote插值

下图可以帮助我们直观理解Borderline SMOTE的基本想法。考虑最近的m=5个样本：

- 对于A而言，最近的5个样本均属于多数类样本，认为A为噪声点，在其附近产生少数类样本会使得噪声的影响更大

- 对于C而言，最近的5个样本中有3个属于少数类样本，2个属于多数类样本，此类样本是不容易被错分的，认为C为安全点

- 对于B而言，最近的5个样本中有2个属于少数类样本，3个属于多数类样本，此类样本容易被错分，认为B处于少数类的边界上，加入危险集

最终只会对B这类的样本点做SMOTE操作

![](http://mmbiz.qpic.cn/mmbiz/kqd3L9d8WdBWjZqPwSJZKpgbntPuz9ia77oNnmLPoZqTdtwA1pSM8hNoq5Lk1RozDPlKeCgCnvlic6ndIHmjPLtw/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

## 3. 集成方法

### 3.1 SMOTE+Tomek links

具体思想是先通过smote插值扩充数据集,然后剔除Tomek links对.

普通SMOTE方法生成的少数类样本是通过线性差值得到的，在平衡类别分布的同时也扩张了少数类的样本空间，产生的问题是可能原本属于多数类样本的空间被少数类“入侵”（invade），容易造成模型的过拟合

Tomek links对寻找的是那种噪声点或者边界点，可以很好地解决“入侵”的问题




