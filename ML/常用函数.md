### 构建[min,max,median,sum]等统计特征

```python
def agg_numeric(df, group_var, df_name):
    """Aggregates the numeric values in a dataframe. This can
 be used to create features for each instance of the grouping variable.

 Parameters
 --------
 df (dataframe): 
 the dataframe to calculate the statistics on
 group_var (string): 
 the variable by which to group df
 df_name (string): 
 the variable used to rename the columns

 Return
 --------
 agg (dataframe): 
 a dataframe with the statistics aggregated for 
 all numeric columns. Each instance of the grouping variable will have 
 the statistics (mean, min, max, sum; currently supported) calculated. 
 The columns are also renamed to keep track of features created.

 """
    # Remove id variables other than grouping variable
    for col in df:
        if col != group_var and 'SK_ID' in col:
            df = df.drop(columns = col)

    group_ids = df[group_var]
    numeric_df = df.select_dtypes('number')
    numeric_df[group_var] = group_ids

    # Group by the specified variable and calculate the statistics
    agg = numeric_df.groupby(group_var).agg(['count', 'mean', 'max', 'min', 'sum']).reset_index()

    # Need to create new column names
    columns = [group_var]

    # Iterate through the variables names
    for var in agg.columns.levels[0]:
        # Skip the grouping variable
        if var != group_var:
            # Iterate through the stat names
            for stat in agg.columns.levels[1][:-1]:
                # Make a new column name for the variable and stat
                columns.append('%s_%s_%s' % (df_name, var, stat))

    agg.columns = columns
    return agg
```

### 计算变量和目标变量之间的相关性
```python
def target_corrs(df):

    # List of correlations
    corrs = []

    # Iterate through the columns 
    for col in df.columns:
        print(col)
        # Skip the target column
        if col != 'TARGET':
            # Calculate correlation with the target
            corr = df['TARGET'].corr(df[col])

            # Append the list as a tuple
            corrs.append((col, corr))

    # Sort by absolute magnitude of correlations
    corrs = sorted(corrs, key = lambda x: abs(x[1]), reverse = True)

    return corrs
```

### 对类别型变量的一些衍生
```python
def count_categorical(df, group_var, df_name):
    """Computes counts and normalized counts for each observation
 of `group_var` of each unique category in every categorical variable

 Parameters
 --------
 df : dataframe 
 The dataframe to calculate the value counts for.

 group_var : string
 The variable by which to group the dataframe. For each unique
 value of this variable, the final dataframe will have one row

 df_name : string
 Variable added to the front of column names to keep track of columns

 Return
 --------
 categorical : dataframe
 A dataframe with counts and normalized counts of each unique category in every categorical variable
 with one row for every unique value of the `group_var`.

 """

    # Select the categorical columns
    categorical = pd.get_dummies(df.select_dtypes('object'))

    # Make sure to put the identifying id on the column
    categorical[group_var] = df[group_var]

    # Groupby the group var and calculate the sum and mean
    categorical = categorical.groupby(group_var).agg(['sum', 'mean'])

    column_names = []

    # Iterate through the columns in level 0
    for var in categorical.columns.levels[0]:
        # Iterate through the stats in level 1
        for stat in ['count', 'count_norm']:
            # Make a new column name
            column_names.append('%s_%s_%s' % (df_name, var, stat))

    categorical.columns = column_names

    return categorica
```
### 特征重要性
```python
def plot_feature_importances(df):
    """
 Plot importances returned by a model. This can work with any measure of
 feature importance provided that higher importance is better. 

 Args:
 df (dataframe): feature importances. Must have the features in a column
 called `features` and the importances in a column called `importance

 Returns:
 shows a plot of the 15 most importance features

 df (dataframe): feature importances sorted by importance (highest to lowest) 
 with a column for normalized importance
 """

    # Sort features according to importance
    df = df.sort_values('importance', ascending = False).reset_index()

    # Normalize the feature importances to add up to one
    df['importance_normalized'] = df['importance'] / df['importance'].sum()

    # Make a horizontal bar chart of feature importances
    plt.figure(figsize = (10, 6))
    ax = plt.subplot()

    # Need to reverse the index to plot most important on top
    ax.barh(list(reversed(list(df.index[:15]))), 
            df['importance_normalized'].head(15), 
            align = 'center', edgecolor = 'k')

    # Set the yticks and labels
    ax.set_yticks(list(reversed(list(df.index[:15]))))
    ax.set_yticklabels(df['feature'].head(15))

    # Plot labeling
    plt.xlabel('Normalized Importance'); plt.title('Feature Importances')
    plt.show()

    return df
```
### 删除共性特征
```python
def identify_collinear(df,correlation_threshold):
    corr_matrix = df.corr()
    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k = 1).astype(np.bool))
    to_drop = [column for column in upper.columns if any(upper[column].abs() > correlation_threshold)]
    record_collinear = pd.DataFrame(columns = ['drop_feature', 'corr_feature', 'corr_value'])
    for column in to_drop:
     # Find the correlated features
        corr_features = list(upper.index[upper[column].abs() > correlation_threshold])

        # Find the correlated values
        corr_values = list(upper[column][upper[column].abs() > correlation_threshold])
        drop_features = [column for _ in range(len(corr_features))]    

        # Record the information (need a temp df for now)
        temp_df = pd.DataFrame.from_dict({'drop_feature': drop_features,
                                         'corr_feature': corr_features,
                                         'corr_value': corr_values})

        # Add to dataframe
        record_collinear = record_collinear.append(temp_df, ignore_index = True)
    print('%d features with a correlation magnitude greater than %0.2f.\n' % (len(to_drop),correlation_threshold)
    return record_collinear,to_drop

```


