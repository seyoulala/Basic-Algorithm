#系统环境变量
export HADOOP="${HADOOP_HOME}/bin/hadoop"
export HIVE="${HIVE_HOME}/bin/hive"
export JAVA="${JAVA_HOME}/bin/java"

#hadoop jar
hadoop_jar="${HADOOP_HOME}/share/packages/hadoop2/hadoop-streaming-2.7.2.jar"

#log_util
scheduler_log_script="${util_dir}/logging"

open_log=true

#
#运行hadoop任务的用户名
user="hdfs"

#hive表路径
ods_hive_dir="/ext_dc/dm/ods/" #hive原始表路径
mds_hive_dir="/ext_dc/dm/mds/"
tmp_hive_dir="/ext_dc/dm/tmp/"

## jdbc
#OSS_URL="oss://your-key:your-value@x-bigdata.oss-cn-hangzhou-internal.aliyuncs.com"
OSS_URL = "/"
## rds1
jdbc_url_rds1="jdbc:mysql://192.192.0.27:3306/WKL?autoReconnect=true"

jdbc_username_rds1="etl"

jdbc_passwd_rds1='1qaz@WSX'


#jdbc_passwd_rds1=`echo ss | perl -e 'use MIME::Base64; $_ = decode_base64(your-password); print;'`
#jdbc_passwd_rds2=`echo ss | perl -e 'use MIME::Base64; $_ = decode_base64(your-password); print;'`
