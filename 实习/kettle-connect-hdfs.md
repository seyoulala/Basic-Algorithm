# kettle 连接hive和HDFS配置说明

## 基础文件配置

在使用bigdata组件之前需要进行一些配置,以CDH为例


```bash
drwxrwxr-x 3 xyh xyh    4096 11月 20 13:56 ./
drwxrwxr-x 6 xyh xyh    4096 4月  30  2018 ../
-rw-rw-r-- 1 xyh xyh     879 4月  30  2018 config.properties
-rw-rw-r-- 1 xyh xyh      73 11月 20 13:39 core-site.xml
-rw-rw-r-- 1 xyh xyh      73 11月 20 13:40 hbase-site.xml
-rw-rw-r-- 1 xyh xyh      73 11月 20 13:40 hdfs-site.xml
-rw-rw-r-- 1 xyh xyh     451 11月 20 13:40 hive-site.xml
drwxrwxr-x 4 xyh xyh    4096 11月 20 10:04 lib/
-rw-rw-r-- 1 xyh xyh     801 11月 20 13:40 mapred-site.xml
-rw-rw-r-- 1 xyh xyh 1394963 4月  30  2018 PentahoHadoopShim_hdp26_OSS_Licenses.html
-rw-rw-r-- 1 xyh xyh  353062 4月  30  2018 pentaho-hadoop-shims-hdp26-8.1.2018.05.00-365.jar
-rw-rw-r-- 1 xyh xyh    8610 4月  30  2018 pentaho-hadoop-shims-hdp26-hbase-comparators-8.1.2018.05.00-365.jar
-rw-r--r-- 1 xyh xyh    2661 11月 20 10:26 pwd
-rw-rw-r-- 1 xyh xyh     435 11月 20 13:41 yarn-site.xml


```
从cdh集群中拷贝`core-site.xml`,`hdfs-site.xml`,`hive-site.xml`,`mapred-site.xml`,`yarn-site.xml`文件覆盖到
`/你的安装目录/data-integration/plugins/pentaho-big-data-plugin/hadoop-configurations/cdh513` 下

修改`/data/kettle/data-integration/plugins/pentaho-big-data-plugin`目录下的`plugin.properties`文件



![](cdh/pictures/kettle4.png)
将`active.hadoop.configuration=cdh513`(看你安装的kettle版本在hadoop-configuration下面)


**修改core-site.xml文件**

```bash
<?xml version="1.0" encoding="UTF-8"?>

<!--Autogenerated by Cloudera Manager-->
<configuration>
  <property>
    <name>fs.defaultFS</name>
    <value>hdfs://192.192.0.25:8020</value> #此处将hostname修改为ip地址
  </property>
  <property>
```
上面这些配置完成后，重新打开Spoon，点击左上角工具栏 -> 工具 -> Hadoop Distribution弹出集群类型选择窗口，我们上一步配置的是CDH，所以这里选择【Cloudera CDH】，然后点击【OK】即可

![](cdh/pictures/kettle5.png)

## 创建集群连接
在【Hadoop clusters】分组图标右键菜单中点击【New Cluster】弹出集群配置窗口:

![hdfs](cdh/pictures/kettle1.png)

首先给集群起个名字【Cluster name】；

然后【Storage】选择HDFS；

再然后配置【HDFS】连接信息：如果你的集群未开启NameNode ，那么【Hostname】和【Port】如实填写即可，如果开启了NameNode HA，那么【Hostname】这里就填写HDFS的Namespace（命名空间）

，命名空间即为core-site.xml中fs.defaultFS去掉`hdfs://`后的的属性值。集群未配置访问认证的话，【Username】和【Password】不用填写；



配置完成以后，点击【测试】按钮可以测试一下集群连接，如果配置无误的话，可以看到全是绿色的对勾：


![](cdh/pictures/kettle2.png)


## Hadoop File Output

创建完成集群连接以后，就可以直接输出数据到HDFS上了，使用的是转换中【Big Data】分组下的【Hadoop File Output】组件:

![](cdh/pictures/kettle3.png)

`点击浏览,可以选择hdfs的文件路径`,已经文件的扩展名名都可以设置.

## hive 连接

**将cdh  lib中hive开头的jar包拷贝**覆盖到`/data/kettle/data-integration/plugins/pentaho-big-data-plugin/hadoop-configurations/hdp26/lib`路径下

**jar包位置**

**/opt/cloudera/parcels/CDH/jars**

```bash
-rw-r--r--. 1 root root    126604 9月  20 03:44 hive-accumulo-handler-2.1.1-cdh6.0.1.jar
-rw-r--r--. 1 root root     43751 9月  20 03:44 hive-ant-2.1.1-cdh6.0.1.jar
-rw-r--r--. 1 root root    169973 9月  20 03:44 hive-beeline-2.1.1-cdh6.0.1.jar
-rw-r--r--. 1 root root     11468 9月  20 03:44 hive-classification-2.1.1-cdh6.0.1.jar
-rw-r--r--. 1 root root     46472 9月  20 03:44 hive-cli-2.1.1-cdh6.0.1.jar
-rw-r--r--. 1 root root    417367 9月  20 03:44 hive-common-2.1.1-cdh6.0.1.jar
-rw-r--r--. 1 root root    128424 9月  20 03:44 hive-contrib-2.1.1-cdh6.0.1.jar
-rw-r--r--. 1 root root  10547199 9月  20 03:44 hive-exec-2.1.1-cdh6.0.1-core.jar
-rw-r--r--. 1 root root  35142524 9月  20 03:44 hive-exec-2.1.1-cdh6.0.1.jar
-rw-r--r--. 1 root root    118452 9月  20 03:44 hive-hbase-handler-2.1.1-cdh6.0.1.jar
-rw-r--r--. 1 root root    264821 9月  20 03:44 hive-hcatalog-core-2.1.1-cdh6.0.1.jar
-rw-r--r--. 1 root root     56458 9月  20 03:44 hive-hcatalog-pig-adapter-2.1.1-cdh6.0.1.jar
-rw-r--r--. 1 root root     72194 9月  20 03:44 hive-hcatalog-server-extensions-2.1.1-cdh6.0.1.jar
-rw-r--r--. 1 root root    127315 9月  20 03:44 hive-hcatalog-streaming-2.1.1-cdh6.0.1.jar
-rw-r--r--. 1 root root    682660 9月  20 03:44 hive-hplsql-2.1.1-cdh6.0.1.jar
-rw-r--r--. 1 root root    112474 9月  20 03:44 hive-jdbc-2.1.1-cdh6.0.1.jar
-rw-r--r--. 1 root root  96206153 9月  20 03:44 hive-jdbc-2.1.1-cdh6.0.1-standalone.jar
-rw-r--r--. 1 root root     98705 9月  20 03:44 hive-llap-client-2.1.1-cdh6.0.1.jar
-rw-r--r--. 1 root root    301718 9月  20 03:44 hive-llap-common-2.1.1-cdh6.0.1.jar
-rw-r--r--. 1 root root     30841 9月  20 03:44 hive-llap-ext-client-2.1.1-cdh6.0.1.jar
-rw-r--r--. 1 root root    568749 9月  20 03:44 hive-llap-server-2.1.1-cdh6.0.1.jar
-rw-r--r--. 1 root root     96333 9月  20 03:44 hive-llap-tez-2.1.1-cdh6.0.1.jar
-rw-r--r--. 1 root root   8001375 9月  20 03:44 hive-metastore-2.1.1-cdh6.0.1.jar
-rw-r--r--. 1 root root    701302 9月  20 03:44 hive-orc-2.1.1-cdh6.0.1.jar
-rw-r--r--. 1 root root    919634 9月  20 03:44 hive-serde-2.1.1-cdh6.0.1.jar
-rw-r--r--. 1 root root    509056 9月  20 03:44 hive-service-2.1.1-cdh6.0.1.jar
-rw-r--r--. 1 root root   1557105 9月  20 03:44 hive-service-rpc-2.1.1-cdh6.0.1.jar
-rw-r--r--. 1 root root     53440 9月  20 03:44 hive-shims-0.23-2.1.1-cdh6.0.1.jar
-rw-r--r--. 1 root root      9856 9月  20 03:44 hive-shims-2.1.1-cdh6.0.1.jar
-rw-r--r--. 1 root root    118282 9月  20 03:44 hive-shims-common-2.1.1-cdh6.0.1.jar
-rw-r--r--. 1 root root     16295 9月  20 03:44 hive-shims-scheduler-2.1.1-cdh6.0.1.jar
-rw-r--r--. 1 root root    117077 9月  20 03:44 hive-storage-api-2.1.1-cdh6.0.1.jar
-rw-r--r--. 1 root root     14375 9月  20 03:44 hive-testutils-2.1.1-cdh6.0.1.jar
-rw-r--r--. 1 root root    214618 9月  20 03:44 hive-webhcat-2.1.1-cdh6.0.1.jar
-rw-r--r--. 1 root root    114189 9月  20 03:44 hive-webhcat-java-client-2.1.1-cdh6.0.1.jar

```

**新建一个DB连接**

![](cdh/pictures/kettle6.png)

连接成功





