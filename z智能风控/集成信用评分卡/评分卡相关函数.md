

```text
from sklearn.linear_model import LogisticRegression
'''
第六步：逻辑回归模型。
要求：
1，变量显著
2，符号为负
'''
y = trainData['y']
x = trainData[multi_analysis]

lr_model = LogisticRegression(C=0.1)
lr_model.fit(x,y)
trainData['prob'] = lr_model.predict_proba(x)[:,1]

# 评分卡刻度 
def cal_scale(score,odds,PDO,model):
    """
    odds：设定的坏好比
    score:在这个odds下的分数
    PDO: 好坏翻倍比
    model:逻辑回归模型
    
    return :A,B,base_score
    """
    B = PDO/np.log(2)
    A = score+B*np.log(odds)
    # base_score = A+B*model.intercept_[0]
    print('B: {:.2f}'.format(B))
    print('A: {:.2f}'.format(A))
    # print('基础分为：{:.2f}'.format(base_score))
    return A,B
    
#假设基础分为50，odds为5%，PDO为10，可以自行调整。这一步是为了计算出A和B。    
cal_scale(50,0.05,10,lr_model)

def Prob2Score(prob, A,B):
    #将概率转化成分数且为正整数
    y = np.log(prob/(1-prob))
    return float(A-B*y)

trainData['score'] = trainData['prob'].map(lambda x:Prob2Score(x, 6.78,14.43))
```

![img](/Volumes/disk2/Basic-Algorithm/z智能风控/img/v2-851d1fab5eeddd93e46fae5b0a20eb02_1440w.png)

　可以看到，评分越高，违约概率越低。网上很多实现评分卡映射的代码，都没太看懂,这个是根据逻辑来写的，有时间再把映射逻辑整理一下。

### **1. 得分的KS曲线**

　和模型的KS曲线一样，只不过横坐标的概率变成了得分。 直接放上代码。

```text
# 得分的KS 
def plot_score_ks(df,score_col,target):
    """
    df:数据集
    target:目标变量的字段名
    score_col:最终得分的字段名
    """
    total_bad = df[target].sum()
    total_good = df[target].count()-total_bad
    score_list = list(df[score_col])
    target_list = list(df[target])
    items = sorted(zip(score_list,target_list),key=lambda x:x[0]) 
    step = (max(score_list)-min(score_list))/200 
    
    score_bin=[] 
    good_rate=[] 
    bad_rate=[] 
    ks_list = [] 
    for i in range(1,201):
        idx = min(score_list)+i*step 
        score_bin.append(idx) 
        target_bin = [x[1] for x in items if x[0]<idx]  
        bad_num = sum(target_bin)
        good_num = len(target_bin)-bad_num 
        goodrate = good_num/total_good 
        badrate = bad_num/total_bad
        ks = abs(goodrate-badrate) 
        good_rate.append(goodrate)
        bad_rate.append(badrate)
        ks_list.append(ks)
        
    fig = plt.figure(figsize=(8,6))
    ax = fig.add_subplot(1,1,1)
    ax.plot(score_bin,good_rate,color='green',label='good_rate')
    ax.plot(score_bin,bad_rate,color='red',label='bad_rate')
    ax.plot(score_bin,ks_list,color='blue',label='good-bad')
    ax.set_title('KS:{:.3f}'.format(max(ks_list)))
    ax.legend(loc='best')
    return plt.show(ax)
```

![img](https://pic1.zhimg.com/80/v2-cecfe4d8ca6ee45a83cc0be4e65e4ce8_1440w.jpg)

### **2. PR曲线**

![img](/Volumes/disk2/Basic-Algorithm/z智能风控/img/v2-395686d12eb924dd213e108c00450adf_1440w.png)

　还是这个混淆矩阵的图，P是查准率、精确率，R是查全率、召回率。这两个指标时既矛盾又统一的。因为为了提高精确率P，就是要更准确地预测正样本，但此时往往会过于保守而漏掉很多没那么有把握的正样本，导致召回率R降低。
　同ROC曲线的形成一样，PR曲线的形成也是不断移动截断点形成不同的(R,P)绘制成一条线。

![img](/Volumes/disk2/Basic-Algorithm/z智能风控/img/v2-c176082f6f37e0903d5a8c59127414da_1440w.png)



　当接近原点时，召回率R接近于0，精确率P较高，说明得分前几位的都是正样本。随着召回率的增加，精确率整体下降，当召回率为1时，说明所有的正样本都被挑了出来，此时的精确率很低，其实就是相当于你将大部分的样本都预测为正样本。注意，只用某个点对应的(R,P)无法全面衡量模型的性能，必须要通过PR曲线的整体表现。此外，还有F1 score和ROC曲线也能反映一个排序模型的性能。

- PR曲线和ROC曲线的区别
  　当正负样本的分布发生变化时，ROC曲线的形状基本不变，PR曲线形状会发生剧烈变化。上图中PR曲线整体较低就是因为正负样本不均衡导致的。因为比如评分卡中坏客户只有1%，好客户有99%,将全部客户预测为好客户，那么准确率依然有99%。虽然模型整体的准确率很高，但并不代表对坏客户的分类准确率也高，这里坏客户的分类准确率为0，召回率也为0。

```text
# PR曲线
def plot_PR(df,score_col,target,plt_size=None):
    """
    df:得分的数据集
    score_col:分数的字段名
    target:目标变量的字段名
    plt_size:绘图尺寸
    
    return: PR曲线
    """
    total_bad = df[target].sum()
    score_list = list(df[score_col])
    target_list = list(df[target])
    score_unique_list = sorted(set(list(df[score_col])))
    items = sorted(zip(score_list,target_list),key=lambda x:x[0]) 

    precison_list = []
    tpr_list = []
    for score in score_unique_list:
        target_bin = [x[1] for x in items if x[0]<=score]  
        bad_num = sum(target_bin)
        total_num = len(target_bin)
        precison = bad_num/total_num
        tpr = bad_num/total_bad
        precison_list.append(precison)
        tpr_list.append(tpr)
    
    plt.figure(figsize=plt_size)
    plt.title('PR曲线')
    plt.xlabel('查全率')
    plt.ylabel('精确率')
    plt.plot(tpr_list,precison_list,color='tomato',label='PR曲线')
    plt.legend(loc='best')
    return plt.show()
```

### **3.得分分布图**

　理想中最好的评分卡模型应该是将好坏客户完全区分出来，但是实际中好坏用户的评分会有一定的重叠，我们要做的尽量减小重叠。
　另外好坏用户的得分分布最好都是正态分布，如果呈双峰或多峰分布，那么很有可能是某个变量的得分过高导致，这样对评分卡的稳定性会有影响。

![img](/Volumes/disk2/Basic-Algorithm/z智能风控/img/v2-3d8edd40a44d2ef59d5cb02c7266dfbf_1440w.png)



```text
# 得分分布图
def plot_score_hist(df,target,score_col,plt_size=None,cutoff=None):
    """
    df:数据集
    target:目标变量的字段名
    score_col:最终得分的字段名
    plt_size:图纸尺寸
    cutoff :划分拒绝/通过的点
    
    return :好坏用户的得分分布图
    """    
    plt.figure(figsize=plt_size)
    x1 = df[df[target]==1][score_col]
    x2 = df[df[target]==0][score_col]
    sns.kdeplot(x1,shade=True,label='坏用户',color='hotpink')
    sns.kdeplot(x2,shade=True,label='好用户',color ='seagreen')
    plt.axvline(x=cutoff)
    plt.legend()
    return plt.show()
```

### **4.得分明细表**

　按分数段区分，看不同分数段的好坏样本情况、违约率等指标。

![img](/Volumes/disk2/Basic-Algorithm/z智能风控/img/v2-5535e14a435ea5a2d51a3ed044a0abcc_1440w.png)



　可以看到高分段的违约概率明显比低分段低，说明评分卡的效果是显著的。

```text
# 得分明细表 
def score_info(df,score_col,target,x=None,y=None,step=None):
    """
    df:数据集
    target:目标变量的字段名
    score_col:最终得分的字段名
    x:最小区间的左值
    y:最大区间的右值
    step:区间的分数间隔
    
    return :得分明细表
    """
    df['score_bin'] = pd.cut(df[score_col],bins=np.arange(x,y,step),right=True)
    total = df[target].count()
    bad = df[target].sum()
    good = total - bad
    
    group = df.groupby('score_bin')
    score_info_df = pd.DataFrame()
    score_info_df['用户数'] = group[target].count()
    score_info_df['坏用户'] = group[target].sum()
    score_info_df['好用户'] = score_info_df['用户数']-score_info_df['坏用户']
    score_info_df['违约占比'] = score_info_df['坏用户']/score_info_df['用户数']
    score_info_df['累计用户'] = score_info_df['用户数'].cumsum()
    score_info_df['坏用户累计'] = score_info_df['坏用户'].cumsum()
    score_info_df['好用户累计'] = score_info_df['好用户'].cumsum()
    score_info_df['坏用户累计占比'] = score_info_df['坏用户累计']/bad 
    score_info_df['好用户累计占比'] = score_info_df['好用户累计']/good
    score_info_df['累计用户占比'] = score_info_df['累计用户']/total 
    score_info_df['累计违约占比'] = score_info_df['坏用户累计']/score_info_df['累计用户']
    score_info_df = score_info_df.reset_index()
    return score_info_df
```

### **5.提升图和洛伦兹曲线**

　假设目前有10000个样本，坏用户占比为30%，我们做了一个评分卡（分数越低，用户坏的概率越高），按照评分从低到高划分成10等份（每个等份用户数为1000），计算每等份的坏用户占比，如果评分卡效果很好，那么越靠前的等份里，包含的坏用户应该越多，越靠后的等份里，包含的坏用户应该要更少。作为对比，如果不对用户评分，按照总体坏用户占比30%来算，每个等份中坏用户占比也是30%。将这两种方法的每等份坏用户占比放在一张柱状图上进行对比，就是提升图。

![img](/Volumes/disk2/Basic-Algorithm/z智能风控/img/v2-40457f214b493629d6176431f4f5cff6_1440w.png)



　将这两种方法的累计坏用户占比放在一张曲线图上，就是洛伦兹曲线图。

![img](/Volumes/disk2/Basic-Algorithm/z智能风控/img/v2-68a12951293e00425661466712a74f2a_1440w.png)



　此外，洛伦兹曲线可以比较两个评分卡的优劣，例如下图中虚线对应的分数假设是600分，那么在600分这cutoff点下，A和B的拒绝率都是40%，但A可以拒绝掉88%的坏用户，B只能拒掉78%的坏用户，说明A评分卡的效果更好。

![img](https://pic4.zhimg.com/80/v2-ce2bf00005d4c90442fe878a2b7271b3_1440w.jpg)



```text
# 绘制提升图和洛伦兹曲线
def plot_lifting(df,score_col,target,bins=10,plt_size=None):
    """
    df:数据集，包含最终的得分
    score_col:最终分数的字段名
    target:目标变量名
    bins:分数划分成的等份数
    plt_size:绘图尺寸
    
    return:提升图和洛伦兹曲线
    """
    score_list = list(df[score_col])
    label_list = list(df[target])
    items = sorted(zip(score_list,label_list),key = lambda x:x[0])
    step = round(df.shape[0]/bins,0)
    bad = df[target].sum()
    all_badrate = float(1/bins)
    all_badrate_list = [all_badrate]*bins
    all_badrate_cum = list(np.cumsum(all_badrate_list))
    all_badrate_cum.insert(0,0)
    
    score_bin_list=[]
    bad_rate_list = []
    for i in range(0,bins,1):
        index_a = int(i*step)
        index_b = int((i+1)*step)
        score = [x[0] for x in items[index_a:index_b]]
        tup1 = (min(score),)
        tup2 = (max(score),)
        score_bin = tup1+tup2
        score_bin_list.append(score_bin)
        label_bin = [x[1] for x in items[index_a:index_b]]
        bin_bad = sum(label_bin)
        bin_bad_rate = bin_bad/bad
        bad_rate_list.append(bin_bad_rate)
    bad_rate_cumsum = list(np.cumsum(bad_rate_list))
    bad_rate_cumsum.insert(0,0)
    
    plt.figure(figsize=plt_size)
    x = score_bin_list
    y1 = bad_rate_list
    y2 = all_badrate_list
    y3 = bad_rate_cumsum
    y4 = all_badrate_cum
    plt.subplot(1,2,1)
    plt.title('提升图')
    plt.xticks(np.arange(bins)+0.15,x,rotation=90)
    bar_width= 0.3
    plt.bar(np.arange(bins),y1,width=bar_width,color='hotpink',label='score_card')
    plt.bar(np.arange(bins)+bar_width,y2,width=bar_width,color='seagreen',label='random')
    plt.legend(loc='best')
    plt.subplot(1,2,2)
    plt.title('洛伦兹曲线图')
    plt.plot(y3,color='hotpink',label='score_card')
    plt.plot(y4,color='seagreen',label='random')
    plt.xticks(np.arange(bins+1),rotation=0)
    plt.legend(loc='best')
    return plt.show()
plot_lifting(trainData,'score','y',bins=10,plt_size=(10,5))
```

### **6.设定cutoff**

　cutoff即根据评分划分通过/拒绝的点，其实就是看不同的阈值下混淆矩阵的情况。设定cutoff时有两个指标，一个是误伤率，即FPR，就是好客户中有多少被预测为坏客户而拒绝。另一个是拒绝率，就是这样划分的情况下有多少客户被拒绝。

![img](https://pic4.zhimg.com/80/v2-8375d48599f3c586dd9f17bf26bbd00f_1440w.jpg)



```text
# 设定cutoff点，衡量有效性
def rule_verify(df,col_score,target,cutoff):
    """
    df:数据集
    target:目标变量的字段名
    col_score:最终得分的字段名    
    cutoff :划分拒绝/通过的点
    
    return :混淆矩阵
    """
    df['result'] = df.apply(lambda x:30 if x[col_score]<=cutoff else 10,axis=1)
    TP = df[(df['result']==30)&(df[target]==1)].shape[0] 
    FN = df[(df['result']==30)&(df[target]==0)].shape[0] 
    bad = df[df[target]==1].shape[0] 
    good = df[df[target]==0].shape[0] 
    refuse = df[df['result']==30].shape[0] 
    passed = df[df['result']==10].shape[0] 
    
    acc = round(TP/refuse,3) 
    tpr = round(TP/bad,3) 
    fpr = round(FN/good,3) 
    pass_rate = round(refuse/df.shape[0],3) 
    matrix_df = pd.pivot_table(df,index='result',columns=target,aggfunc={col_score:pd.Series.count},values=col_score) 
    
    print('精确率:{}'.format(acc))
    print('查全率:{}'.format(tpr))
    print('误伤率:{}'.format(fpr))
    print('规则拒绝率:{}'.format(pass_rate))
    return matrix_df
```

### **1.AUC**

　AUC值指的是ROC曲线下面积大小，该值能够量化反映基于ROC曲线衡量的模型性能。所以，需要了解ROC曲线的绘制方法。
　首先，需要了解TPR(真阳性率)和FPR(假阳性率)。TPR就是P个正样本中被预测为正的概率，FPR是N个负样本中被预测为正样本的概率。(FPR,TPR)形成ROC曲线上的一个点。

![img](https://pic1.zhimg.com/80/v2-356acc2190bf82a5dd84a1c1bc742cac_1440w.jpg)



　ROC曲线通过不断移动截断点来生成不同的(FPR,TPR)，可以理解为评分卡中的cut-off在不断变化。

![img](https://pic4.zhimg.com/80/v2-7f8dc1d447b6674437b8f99407fd0f77_1440w.jpg)



　绘制出ROC曲线之后，AUC就是ROC曲线下的面积。此外ROC曲线相对应的P-R曲线之间的区别，有兴趣的可以研究下，这里不再赘述。下面附上代码：

```python
def plot_roc(y_label,y_pred):
    """
    y_label:测试集的y
    y_pred:对测试集预测后的概率
    
    return:ROC曲线
    """
    tpr,fpr,threshold = metrics.roc_curve(y_label,y_pred) 
    AUC = metrics.roc_auc_score(y_label,y_pred) 
    fig = plt.figure(figsize=(6,4))
    ax = fig.add_subplot(1,1,1)
    ax.plot(tpr,fpr,color='blue',label='AUC=%.3f'%AUC) 
    ax.plot([0,1],[0,1],'r--')
    ax.set_ylim(0,1)
    ax.set_xlim(0,1)
    ax.set_title('ROC')
    ax.legend(loc='best')
    return plt.show(ax)
```

![img](https://pic3.zhimg.com/80/v2-d0d01dcbe487a8a983727cf29014c366_1440w.jpg)

### **2.KS**

　KS曲线与ROC曲线非常的类似。KS曲线是两条线，其横轴是阈值，纵轴是TPR与FPR。两条曲线之间之间相距最远的地方对应的阈值，就是最能划分模型的阈值。KS曲线是用来衡量分类型模型准确度的工具。

KS的计算步骤如下：

1. 计算每个评分区间的好坏账户数。
2. 计算每个评分区间的累计好账户数占总好账户数比率(good%)和累计坏账户数占总坏账户数比率(bad%)。
3. 计算每个评分区间累计坏账户占比与累计好账户占比差的绝对值（累计good%-累计bad%），然后对这些绝对值取最大值即得此评分卡的K-S值。

```text
def plot_model_ks(y_label,y_pred):
    """
    y_label:测试集的y
    y_pred:对测试集预测后的概率
    
    return:KS曲线
    """
    pred_list = list(y_pred) 
    label_list = list(y_label)
    total_bad = sum(label_list)
    total_good = len(label_list)-total_bad 
    items = sorted(zip(pred_list,label_list),key=lambda x:x[0]) 
    step = (max(pred_list)-min(pred_list))/200 
    
    pred_bin=[]
    good_rate=[] 
    bad_rate=[] 
    ks_list = [] 
    for i in range(1,201): 
        idx = min(pred_list)+i*step 
        pred_bin.append(idx) 
        label_bin = [x[1] for x in items if x[0]<idx] 
        bad_num = sum(label_bin)
        good_num = len(label_bin)-bad_num  
        goodrate = good_num/total_good 
        badrate = bad_num/total_bad
        ks = abs(goodrate-badrate) 
        good_rate.append(goodrate)
        bad_rate.append(badrate)
        ks_list.append(ks)
    
    fig = plt.figure(figsize=(8,6))
    ax = fig.add_subplot(1,1,1)
    ax.plot(pred_bin,good_rate,color='green',label='good_rate')
    ax.plot(pred_bin,bad_rate,color='red',label='bad_rate')
    ax.plot(pred_bin,ks_list,color='blue',label='good-bad')
    ax.set_title('KS:{:.3f}'.format(max(ks_list)))
    ax.legend(loc='best')
    return plt.show(ax)
```

![img](https://pic3.zhimg.com/80/v2-155e77603b3132f1b34824ebd50bce56_1440w.jpg)

　此外还有基尼系数，列出三者的综合判断标准：

![img](https://pic1.zhimg.com/80/v2-bfef5ad42cf6f311789186f23a1885a4_1440w.jpg)



### **3.交叉验证**

　交叉验证是为了评估模型的泛化能力。

1. k折交叉验证

![img](https://pic3.zhimg.com/80/v2-e8b69b41b0bb704235fd888bae105df6_1440w.jpg)



- 第一步，不重复抽样将原始数据随机分为 k 份。
- 第二步，每一次挑选其中 1 份作为测试集，剩余 k-1 份作为训练集用于模型训练。
- 第三步，重复第二步 k 次，这样每个子集都有一次机会作为测试集，其余子集作为训练集。在每个训练集上训练后得到一个模型，用这个模型在相应的测试集上测试，计算并保存模型的评估指标。
- 第四步，计算 k 组测试结果的平均值作为模型精度的估计，并作为当前 k 折交叉验证下模型的性能指标

1. 时间序列交叉验证
   　金融数据具有时间周期性的特点，不同时间段的样本分布和变量分布会有一定差异，首先在选取建模的样本时就要考虑是否能代表总体的样本分布或者近段时间用户的状态。在做交叉验证时也需要考虑到时间周期这一点，例如我们选取的是1月份至10月份的数据，可以借鉴K折验证的思想，将数据集按照月份分为 10份，每次挑选其中一份作为测试集，其他作为训练集，得到10组的验证结果，观察随着月份的推移，模型的结果是否有比较大的趋势变化，这个也可以反映出样本是否稳定。如果变化较明显，则需要分析是什么原因导致的，是内部大的业务政策，还是外部的经济环境。

```text
# 交叉验证
def cross_verify(x,y,estimators,fold,scoring='roc_auc'):
    """
    x:自变量的数据集
    y:target的数据集
    estimators：验证的模型
    fold：交叉验证的策略
    scoring:评级指标，默认auc
    
    return:交叉验证的结果
    """
    cv_result = cross_val_score(estimator=estimators,X=x,y=y,cv=fold,n_jobs=-1,scoring=scoring)
    print('CV的最大AUC为:{}'.format(cv_result.max()))
    print('CV的最小AUC为:{}'.format(cv_result.min()))
    print('CV的平均AUC为:{}'.format(cv_result.mean()))
    plt.figure(figsize=(6,4))
    plt.title('交叉验证的评价指标分布图')
    plt.boxplot(cv_result,patch_artist=True,showmeans=True,
            boxprops={'color':'black','facecolor':'yellow'},
            meanprops={'marker':'D','markerfacecolor':'tomato'},
            flierprops={'marker':'o','markerfacecolor':'red','color':'black'},
            medianprops={'linestyle':'--','color':'orange'})
    return plt.show()
```

画出的效果图如下：

![img](https://pic3.zhimg.com/80/v2-b6e57f74facf46981253e6334fc098ae_1440w.jpg)



### **4.学习曲线**

　学习曲线的纵轴是训练集的大小，横轴是模型在训练集上和交叉验证集上的平均得分（准确率），可以反映随着训练集大小的改变，模型在训练集和验证集上的误差得分情况。进而判定模型的拟合情况。

![img](https://pic3.zhimg.com/80/v2-0f3d1f6fc078fdb9a1a6e33697a27aee_1440w.jpg)



- 第一张图中，随着训练集不断增大，模型在训练集和验证集上的得分不断靠近，但两者的得分都比较低，存在欠拟合的问题。
- 第二张图中，随着训练集增大，模型在训练集和验证集上的得分不断靠近，且两者的得分都比较高，说明模型的拟合比较良好。
  更多关于学习曲线的问题可以查看官方文档，链接是**[学习曲线](https://link.zhihu.com/?target=https%3A//scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html%23sphx-glr-auto-examples-model-selection-plot-learning-curve-py)**
  注意：金融模型很容易出现过拟合的问题，解决过拟合的方法有很多，例如增加建模样本，正则化等，例如逻辑回归里可以选择L1正则化或L2正则化，且可设置正则化的强度，另外做评分卡时，入模的变量不宜太多，太多的变量会使模型过于复杂，容易出现过拟合，一般应限制在15个以下。

```text
# 学习曲线
def plot_learning_curve(estimator,x,y,cv=None,train_size = np.linspace(0.1,1.0,5),plt_size =None):
    """
    estimator :画学习曲线的基模型
    x:自变量的数据集
    y:target的数据集
    cv:交叉验证的策略
    train_size:训练集划分的策略
    plt_size:画图尺寸
    
    return:学习曲线
    """
    from sklearn.model_selection import learning_curve
    train_sizes,train_scores,test_scores = learning_curve(estimator=estimator,
                                                          X=x,
                                                          y=y,
                                                          cv=cv,
                                                          n_jobs=-1,
                                                          train_sizes=train_size)
    train_scores_mean = np.mean(train_scores,axis=1)
    train_scores_std = np.std(train_scores,axis=1)
    test_scores_mean = np.mean(test_scores,axis=1)
    test_scores_std = np.std(test_scores,axis=1)
    plt.figure(figsize=plt_size)
    plt.xlabel('Training-example')
    plt.ylabel('score')
    plt.fill_between(train_sizes,train_scores_mean-train_scores_std,
                     train_scores_mean+train_scores_std,alpha=0.1,color='r')
    plt.fill_between(train_sizes,test_scores_mean-test_scores_std,
                     test_scores_mean+test_scores_std,alpha=0.1,color='g')
    plt.plot(train_sizes,train_scores_mean,'o-',color='r',label='Training-score')
    plt.plot(train_sizes,test_scores_mean,'o-',color='g',label='cross-val-score')
    plt.legend(loc='best')
    return plt.show()
```

### **5.混淆矩阵**

　混淆矩阵的指标有精确率，查全率(召回率)，误伤率。这三个指标的值取决于评分卡的cutoff点怎么设置。评分卡最后会输出一个评分分布表，根据评分的等级和业务目标来选择适当的cutoff点，从而计算出这三个指标。

![img](https://pic4.zhimg.com/80/v2-395686d12eb924dd213e108c00450adf_1440w.jpg)



```text
# 混淆矩阵 /分类报告
def plot_matrix_report(y_label,y_pred): 
    """
    y_label:测试集的y
    y_pred:对测试集预测后的概率
    
    return:混淆矩阵
    """
    matrix_array = metrics.confusion_matrix(y_label,y_pred)
    plt.matshow(matrix_array, cmap=plt.cm.summer_r)
    plt.colorbar()

    for x in range(len(matrix_array)): 
        for y in range(len(matrix_array)):
            plt.annotate(matrix_array[x,y], xy =(x,y), ha='center',va='center')

    plt.xlabel('True label')
    plt.ylabel('Predict label')
    print(metrics.classification_report(y_label,y_pred))
    return plt.show()
```

![img](https://pic2.zhimg.com/80/v2-0ad66f7cce2044edf4b714257824e09d_1440w.jpg)

