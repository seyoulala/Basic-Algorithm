### 幸存者偏差

广义的幸存者偏差用统计学的专业术语来解释是——“**选择偏倚**”，即我们在进行统计的时候忽略了样本的随机性和全面性，用局部样本代替了总体随机样本，从而对总体的描述出现偏倚。

在金融信贷场景中，放款机构会通过模型评分筛选用户，评分较好的用户可以获得放款，评分较差的用户直接被拒绝，机构只能获得放款用户样本的好坏标签，对于大量拒绝用户的还款情况无法获得。

随着时间的推移，机构手中的训练样本都是“评分较好”的通过用户，而没有“评分较差”的拒绝用户，由此训练的模型在“评分较好”用户中表现越来越好，在“评分较差”用户中却无法得到任何验证。

但是，金融风控模型真实面对的客群却包括了“评分较差”的用户，模型在“评分较差”用户中无法得到验证，导致训练的模型越来越偏离实际情况，甚至通过了大量应该被拒绝的坏用户，致使大量坏账出现，直接带来巨大经济损失。

用下图示意的话，在客户全集为A的情况下，放款机构仅能通过分析子集幸存者A1的还款与行为数据寻找区分客户好坏的标签，但却不得不把这种标签推广应用在包括子集沉默者A2在内的全集上，而从A1取得的好坏标签在A2中可能并不成立。

![img](https://img.weiyangx.com/2019/01/609bb90dcf1bd7311a93.png)

### 03 使用“拒绝推断”解决幸存者偏差

**拒绝推断（Reject Inference）**，即推断建模总体中被拒绝的客户样本可能出现的结果。拒绝推断是建立申请评分模型时的特有问题。如果我们能够顺利运用某些方法成功地推断出被拒绝的客户的信用表现（即是好客户还是坏客户），那么我们就得到一个较完整的建模总体和建模样本。

**拒绝推断的方法**

● **接受部分坏客户**

解决样本选择偏差的最直接有效的方法就是随机抽取未被授信的客户，对其进行授信，观察未来表现。对于这部分客户加以一定的权重与那些原本被授信的客户合起来作为模型开发的样本。

**但是这种方法在现实中很难被风险管理部门所接受，因为未被授信的客户一般被认为存在拖欠行为的可能性较大，对这部分客户进行授信，风险也往往较高，易带来损失。**

● **两阶段加权的方法**

（核心基于诺贝尔奖获得者Heckman的两阶段模型）

这里先解释下Heckman的两阶段模型。

Heckman 在1974年发表的《Shadow Price, Market Wages and Labor Supply》（影子价格、市场工资与劳动供给）中研究了工资与教育程度的关系。很显然，研究者只可能从有工作的人们那儿获得有关工资的数据。根据这些数据，研究者可以绘制成下图这样的分布图。图1中W表示工资，X表示受教育程度，可获得工资数据是图中的实心点。这样，我们研究所得到的两者的关系就如虚线所示。

![img](https://img.weiyangx.com/2019/01/6c26e7e06608f581fe72.png)

但是，这个关系是有偏差的。因为有不小比例的人没有参加工作，对这些人，我们可以了解他的教育程度，却不知道他一小时可以挣多少钱。一般地，人们是否参加工作取决于实际可得的工资与意愿工资，当工资低于意愿工资时，人们就会选择不工作。把不工作这部分人也搬到我们的图上，其分布就是图中的空心点。这时，工资与教育程度的关系就是图中的实线。可以发现，如果只拿实心点研究，得出的结论实际上低估了受教育程度对工资的影响。

在Heckman 1979年发表的另一篇论文《Sample selection bias as a specification error》（样本选择偏差导致的设定误差）中给出了这一问题的具体解决方法。首先，算出不同教育水平的人，参加工作的概率各有多大，这可以通过经验数据模型得到。然后，删去不工作之人的样本，将余留的样本点依其工作概率的不同，垂直往下位移。**工作概率愈小，向下位移愈大；工作概率愈大，向下位移愈小。工作概率百分之百的，不作位移。**(下图，实心点下移到由空心点标示的新位置。)

![img](https://img.weiyangx.com/2019/01/5720a37397b7532a3f26.png)

然后，对位移后的样本点，求出其回归线。理论上可以证明，这条回归线，与第一个图中标出的真实关系线，应当是一致的(参见图3)。

![img](https://img.weiyangx.com/2019/01/6a704f229c6acb72e5b1.png)

回到我们的问题当中，假设被拒绝的申请者行为模式与被授信的申请者行为模式相似，其基本思想是加权被授信的申请者，使得被授信的申请者能够代表被拒绝的申请者的行为。该方法分为两个阶段。

**第一阶段**，建立一个拒绝/批准模型，用来预测一个申请者被拒绝/批准的概率。然后假设拒绝/批准概率相近的客户具有近似的风险特征, 因此考虑将拒绝/批准概率分成若干段，每段的好坏账户能代表该段内的被拒客户的特征，因此利用这些好坏账户可以推测被拒帐户中的好坏。

**第二阶段**，为每一个样本计算出用于修正样本选择偏差的权重修正因子，从而建立有权重修正因子的违约预测模型。

具体操作如下：

**1.** 对所有样本账户先构建一个粗略的拒绝/批准模型，其中批准账户包括“好账户”、“坏账户”，据此得到对所有账户的预测的拒绝概率。该拒绝/批准模型仅用于加权调整，采用的变量可以放宽。

**2.** 将预测的拒绝概率分成0—0.1, 0.1—0.2,……，0.9—1.0共10段，计算每段的好坏账户、拒绝账户的个数，计算每段的权重修正因子：(好账户数+坏账户数+被拒账户数)/(好账户数+坏账户数)。

**3.** 将每段的帐户的原有权重和该段的权重修正因子相乘，得到新的权重变量，这个新的权重变量用于模型拟合与调整。



**下面进行模型的初步拟合——拒绝/批准模型。**

拒绝/批准模型的目标变量定义为是否批准申请的二元变量，对开发集中的所有记录采用逐步Logistic 回归方法，根据回归的结果，对所有开发集帐户进行评估，按照评分值大小排序分成10组，组内每个帐户的权重设为该组所有帐户数与组内所有被授信申请者数的比值，获得加权权重。

利用权重修正因子，对所有被授信申请者采用有加权的逐步回归方法，经过显著性检验、方向性检验、共线性检验、稳定性检验等步骤，获得最终的评分模型。使用拒绝推断模型后，测试集的模型性能从之前的KS=32.67%提高到了KS=35.89%。

在信贷风险管理中，作为信用评分的一类，申请评分具有其特殊性，容易出现幸存者偏差效应。

**通过拒绝推断的方法，可以提高风控模型性能。但是如果采用接受部分坏客户的方式会给机构带来潜在的损失，成本高，在操作上也存在难度；而两阶段加权的应用基于统计假设，实践也证明了其修正样本选择偏差的效果，可以有效地提高申请评分模型的预测能力。**



### 增量学习

增量学习主要解决的问题是遗忘性灾难，即平衡新知识和旧知识之间的关系。xgboost可以实现增量学习，先用历史样本训练前几颗树，然后用新的样本学习后面的树，从而平衡新样本和旧样本之间的关系。



## 使用GMM来生成一些样本

由于GMM本身是一个生成式模型，当拟合出一个GMM后，可以从该模型的每一个分布成分中生成符合该分布的新样本。

**如何生成新的样本呢？**

1. 根据历史样本使用GMM进行聚类，得到生成模型，再利用生成模型生成新的样本点，并带入现有样本进行协同训练。因为新生成的样本点与旧样本点服从相同分布，但不完全重合，所以一定程度上可以使得模型有着更强的泛化能力。

**如何确定GMM中成分的个数呢？**

可以使用赤池信息准则(AIC) 和贝叶斯信息准则(BIC).

### AIC

AIC是衡量统计模型拟合优良性的一种标准，它建立在熵的概念上，提供了权衡估计模型复杂度和拟合数据优良性的标准。

通过情况下，AIC定义为: AIC=2k -2lnL.

其中K是模型参数个数，L是似然函数。从一组可供选择的模型中选择最佳模型时，通常选择AIC最小的模型。因为当两个模型存在较大的差异时，差异主要体现在似然函数项上。当似然函数差异不显著时，模型的复杂度会起作用，从而表明参数个数少的模型是较好的选择。一般而言模型复杂度提高也就是K变大，似然函数L也会增大，从而使AIC变小，但是k过大时，似然函数增速减缓，导致AIC增大。模型过于复杂容易造成过拟合。



### BIC

BIC中也引入了与模型参数个数相关的惩罚项，BIC的惩罚项比AIC的大。同时要考虑样本数量，样本数量足够多的时候，可以有效防止模型精度过高造成的模型复杂度过高的问题。

BIC: klnn -2lnL

其中k为参数的个数，n为样本数量，L为似然函数。



~~~python
from  sklearn.datasets.samples_generator import make_blobs
from sklearn.datasets import make_moons
from sklearn.mixture import  GaussianMixture as GMM
import  matplotlib.pyplot as plt


Xmoon,ymoon = make_moons(n_samples=100,noise=0.04,random_state=0)
n_components = list(range(1,20))
models= [GMM(n_components=n,covariance_type='full',random_state=0).fit(Xmoon) for n in n_components]
plt.plot(n_components,[m.bic(Xmoon) for m in models],label='BIC')
plt.plot(n_components,[m.aic(Xmoon) for m in models],label='AIC')
plt.legend(loc='best')
plt.show()
~~~



![image-20200310213228250](/Volumes/disk2/Basic-Algorithm/z智能风控/img/aic_bic.png)

从上图中可以看到，BIC在接近7和AIC接近9的时候达到了最优的解。通常在实际使用的时候不会选择太少的高斯分布组建进行聚类，否则难以生成有针对性的特征。但是为防止生成的模型的泛化能力较差，组建的个数通常不会超过20个。